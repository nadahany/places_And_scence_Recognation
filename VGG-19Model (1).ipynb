{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-29T01:36:41.622694Z","iopub.execute_input":"2021-12-29T01:36:41.623553Z","iopub.status.idle":"2021-12-29T01:36:47.728792Z","shell.execute_reply.started":"2021-12-29T01:36:41.623503Z","shell.execute_reply":"2021-12-29T01:36:47.727284Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/ci-sc22-places-and-scene-recognition/train.csv')\nTRAIN_DIR='/kaggle/input/ci-sc22-places-and-scene-recognition/train_images/train_images'\nground_truth = []\nImages = []\nfrom PIL import Image\nimport cv2\nfrom numpy import asarray\nfrom tqdm import tqdm\n","metadata":{"execution":{"iopub.status.busy":"2021-12-29T01:36:47.731429Z","iopub.execute_input":"2021-12-29T01:36:47.731704Z","iopub.status.idle":"2021-12-29T01:36:47.920888Z","shell.execute_reply.started":"2021-12-29T01:36:47.731669Z","shell.execute_reply":"2021-12-29T01:36:47.920115Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def create_data():\n    dataImage = []\n    Label=[]\n    for img in tqdm(os.listdir(TRAIN_DIR)):\n        path = os.path.join(TRAIN_DIR, img)\n        img_data = cv2.imread(path)\n        img_data = cv2.resize(img_data, (150, 150))\n        dataImage.append(img_data)\n        Label.append(data['label'].loc[data['image_name']==img])\n    return dataImage,Label","metadata":{"execution":{"iopub.status.busy":"2021-12-29T01:36:47.922316Z","iopub.execute_input":"2021-12-29T01:36:47.922541Z","iopub.status.idle":"2021-12-29T01:36:47.929651Z","shell.execute_reply.started":"2021-12-29T01:36:47.922510Z","shell.execute_reply":"2021-12-29T01:36:47.929006Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"Data,Label=create_data()\nImg = np.array(Data)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T01:36:47.932079Z","iopub.execute_input":"2021-12-29T01:36:47.932332Z","iopub.status.idle":"2021-12-29T01:38:21.952832Z","shell.execute_reply.started":"2021-12-29T01:36:47.932298Z","shell.execute_reply":"2021-12-29T01:38:21.952090Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def create_dataa():\n    dataImage = []\n    Label=[]\n    for img in tqdm(os.listdir('/kaggle/input/ci-sc22-places-and-scene-recognition/test_images/test_images')):\n        path = os.path.join('/kaggle/input/ci-sc22-places-and-scene-recognition/test_images/test_images', img)\n        img_data = cv2.imread(path)\n        img_data = cv2.resize(img_data, (150, 150))\n        dataImage.append(img_data)\n    return dataImage","metadata":{"execution":{"iopub.status.busy":"2021-12-29T01:38:21.954187Z","iopub.execute_input":"2021-12-29T01:38:21.954440Z","iopub.status.idle":"2021-12-29T01:38:21.960315Z","shell.execute_reply.started":"2021-12-29T01:38:21.954407Z","shell.execute_reply":"2021-12-29T01:38:21.959350Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"test=create_dataa()","metadata":{"execution":{"iopub.status.busy":"2021-12-29T01:38:21.961655Z","iopub.execute_input":"2021-12-29T01:38:21.961902Z","iopub.status.idle":"2021-12-29T01:38:37.396023Z","shell.execute_reply.started":"2021-12-29T01:38:21.961871Z","shell.execute_reply":"2021-12-29T01:38:37.394246Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"Xtrain=[]\nYtrain=[]\nXtest =[]\nYtest =[]\nfor i in range(len(Data)):\n    Xtrain.append(Data[i])\n    Ytrain.append(Label[i])\n\nfor i in range(len(test)):\n    Xtest.append(test[i])\n","metadata":{"execution":{"iopub.status.busy":"2021-12-29T01:38:37.397200Z","iopub.execute_input":"2021-12-29T01:38:37.397624Z","iopub.status.idle":"2021-12-29T01:38:37.415229Z","shell.execute_reply.started":"2021-12-29T01:38:37.397584Z","shell.execute_reply":"2021-12-29T01:38:37.414356Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set(style=\"whitegrid\")\nimport os\nimport glob as gb\nimport cv2\nimport tensorflow as tf\nimport keras","metadata":{"execution":{"iopub.status.busy":"2021-12-29T01:38:37.416866Z","iopub.execute_input":"2021-12-29T01:38:37.417267Z","iopub.status.idle":"2021-12-29T01:38:42.787419Z","shell.execute_reply.started":"2021-12-29T01:38:37.417225Z","shell.execute_reply":"2021-12-29T01:38:42.786685Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from keras import backend as K\n\nfrom keras.layers import Flatten, Dense, Input, Conv2D, MaxPooling2D, Dropout\nfrom keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, TimeDistributed\n\nfrom keras.utils import layer_utils\nfrom keras.utils.data_utils import get_file\n\nfrom tensorflow.keras.utils import to_categorical\nfrom keras.models import Model\nfrom keras.utils import generic_utils\n\nfrom keras import initializers, regularizers\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential, model_from_json,load_model\nfrom keras.layers.core import Dense, Dropout, Activation, Flatten\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.pooling import MaxPooling2D,MaxPool2D\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import (\n    BatchNormalization, SeparableConv2D, MaxPooling2D, Activation, Flatten, Dropout, Dense\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T01:38:42.788554Z","iopub.execute_input":"2021-12-29T01:38:42.790636Z","iopub.status.idle":"2021-12-29T01:38:43.108510Z","shell.execute_reply.started":"2021-12-29T01:38:42.790607Z","shell.execute_reply":"2021-12-29T01:38:43.107812Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"Ytrain=to_categorical(Ytrain)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T01:38:43.111239Z","iopub.execute_input":"2021-12-29T01:38:43.111543Z","iopub.status.idle":"2021-12-29T01:38:43.330213Z","shell.execute_reply.started":"2021-12-29T01:38:43.111504Z","shell.execute_reply":"2021-12-29T01:38:43.329485Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"Ytrain","metadata":{"execution":{"iopub.status.busy":"2021-12-29T01:38:43.331566Z","iopub.execute_input":"2021-12-29T01:38:43.331869Z","iopub.status.idle":"2021-12-29T01:38:43.339509Z","shell.execute_reply.started":"2021-12-29T01:38:43.331830Z","shell.execute_reply":"2021-12-29T01:38:43.338689Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"\nmodel =Sequential()\n#Block1\nmodel.add(Conv2D(input_shape=(150,150,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n\n#Block2\nmodel.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n\n#Block3\nmodel.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n\n#Block4\nmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n\n#Block5\n\nmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n\nmodel.add(Flatten())\n\n\nmodel.add(Dense(units=4096,activation=\"relu\"))\nmodel.add(Dense(units=4096,activation=\"relu\"))\nmodel.add(Dense(units=1000,activation=\"relu\"))\nmodel.add(Dense(units=6, activation=\"softmax\"))\n ","metadata":{"execution":{"iopub.status.busy":"2021-12-29T01:38:43.341031Z","iopub.execute_input":"2021-12-29T01:38:43.341518Z","iopub.status.idle":"2021-12-29T01:38:45.841606Z","shell.execute_reply.started":"2021-12-29T01:38:43.341458Z","shell.execute_reply":"2021-12-29T01:38:45.839990Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"\n\nprint('Model Details are : ')\nprint(model.summary())\n","metadata":{"execution":{"iopub.status.busy":"2021-12-29T01:38:45.843009Z","iopub.execute_input":"2021-12-29T01:38:45.843251Z","iopub.status.idle":"2021-12-29T01:38:45.861344Z","shell.execute_reply.started":"2021-12-29T01:38:45.843217Z","shell.execute_reply":"2021-12-29T01:38:45.860711Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"#KerasModel.compile(optimizer=Optimizer.Adam(0.0001),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\nimport tensorflow.keras.optimizers as Optimizer\nmodel.compile(optimizer=Optimizer.Adam(0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2021-12-29T01:38:45.862960Z","iopub.execute_input":"2021-12-29T01:38:45.863200Z","iopub.status.idle":"2021-12-29T01:38:45.878497Z","shell.execute_reply.started":"2021-12-29T01:38:45.863169Z","shell.execute_reply":"2021-12-29T01:38:45.877651Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"epochs = 35\nXtrain = np.array(Xtrain)\nYtrain =np.array(Ytrain)\nThisModel = model.fit(Xtrain, Ytrain, epochs=epochs,batch_size=64,verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T01:38:45.879725Z","iopub.execute_input":"2021-12-29T01:38:45.880018Z","iopub.status.idle":"2021-12-29T02:07:10.760122Z","shell.execute_reply.started":"2021-12-29T01:38:45.879982Z","shell.execute_reply":"2021-12-29T02:07:10.759341Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"plt.plot(ThisModel.history['loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()\nplt.plot(ThisModel.history['accuracy'])\nplt.title('model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-29T02:07:21.832933Z","iopub.execute_input":"2021-12-29T02:07:21.833219Z","iopub.status.idle":"2021-12-29T02:07:22.810338Z","shell.execute_reply.started":"2021-12-29T02:07:21.833159Z","shell.execute_reply":"2021-12-29T02:07:22.808014Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"#save model\nmodel.save(\"VGG-19model\")","metadata":{"execution":{"iopub.status.busy":"2021-12-29T02:07:10.763579Z","iopub.execute_input":"2021-12-29T02:07:10.763848Z","iopub.status.idle":"2021-12-29T02:07:15.532672Z","shell.execute_reply.started":"2021-12-29T02:07:10.763814Z","shell.execute_reply":"2021-12-29T02:07:15.531983Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(np.array(Xtest))\n\nprint('Prediction Shape is {}'.format(y_pred.shape))\ny_pred","metadata":{"execution":{"iopub.status.busy":"2021-12-29T02:07:15.535457Z","iopub.execute_input":"2021-12-29T02:07:15.535865Z","iopub.status.idle":"2021-12-29T02:07:21.778707Z","shell.execute_reply.started":"2021-12-29T02:07:15.535825Z","shell.execute_reply":"2021-12-29T02:07:21.777893Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"Yfinal=[]\nYfinal = np.array(np.argmax(y_pred,axis=1))","metadata":{"execution":{"iopub.status.busy":"2021-12-29T02:07:21.779867Z","iopub.execute_input":"2021-12-29T02:07:21.780150Z","iopub.status.idle":"2021-12-29T02:07:21.785658Z","shell.execute_reply.started":"2021-12-29T02:07:21.780114Z","shell.execute_reply":"2021-12-29T02:07:21.784338Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"Image_name=[]\ni=0\nfor img in tqdm(os.listdir('/kaggle/input/ci-sc22-places-and-scene-recognition/test_images/test_images')):\n    \n    path = os.path.join('/kaggle/input/ci-sc22-places-and-scene-recognition/test_images/test_images', img)\n    Image_name.append(img)\n    i+=1\n\n","metadata":{"execution":{"iopub.status.busy":"2021-12-29T02:07:21.787207Z","iopub.execute_input":"2021-12-29T02:07:21.787491Z","iopub.status.idle":"2021-12-29T02:07:21.814828Z","shell.execute_reply.started":"2021-12-29T02:07:21.787455Z","shell.execute_reply":"2021-12-29T02:07:21.814048Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"my_submission = pd.DataFrame({'Image_name': Image_name, 'Label': Yfinal})\nmy_submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T02:07:21.816151Z","iopub.execute_input":"2021-12-29T02:07:21.816597Z","iopub.status.idle":"2021-12-29T02:07:21.831748Z","shell.execute_reply.started":"2021-12-29T02:07:21.816562Z","shell.execute_reply":"2021-12-29T02:07:21.831123Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"## ","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}