{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        os.path.join(dirname, filename)\n        #print()\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-28T23:38:31.227528Z","iopub.execute_input":"2021-12-28T23:38:31.22792Z","iopub.status.idle":"2021-12-28T23:38:33.673307Z","shell.execute_reply.started":"2021-12-28T23:38:31.227808Z","shell.execute_reply":"2021-12-28T23:38:33.672532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/ci-sc22-places-and-scene-recognition/train.csv')\nTRAIN_DIR='/kaggle/input/ci-sc22-places-and-scene-recognition/train_images/train_images'\nground_truth = []\nImages = []\nfrom PIL import Image\nimport cv2\nfrom numpy import asarray\nfrom tqdm import tqdm\nfor _, _, images in os.walk('/kaggle/input/ci-sc22-places-and-scene-recognition/train_images/train_images'):\n    print(len(images))\n    for name in images:\n        Images.append(Image.open('/kaggle/input/ci-sc22-places-and-scene-recognition/train_images/train_images/'+name))\n        \n        ground_truth.append(data['label'].loc[data['image_name']==name])","metadata":{"execution":{"iopub.status.busy":"2021-12-28T23:38:33.675079Z","iopub.execute_input":"2021-12-28T23:38:33.675348Z","iopub.status.idle":"2021-12-28T23:39:42.171719Z","shell.execute_reply.started":"2021-12-28T23:38:33.675319Z","shell.execute_reply":"2021-12-28T23:39:42.17076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_data():\n    dataImage = []\n    Label=[]\n    for img in tqdm(os.listdir(TRAIN_DIR)):\n        path = os.path.join(TRAIN_DIR, img)\n        img_data = cv2.imread(path)\n        img_data = cv2.resize(img_data, (150, 150))\n        dataImage.append(img_data)\n        Label.append(data['label'].loc[data['image_name']==img])\n    return dataImage,Label","metadata":{"execution":{"iopub.status.busy":"2021-12-28T23:39:42.173013Z","iopub.execute_input":"2021-12-28T23:39:42.173273Z","iopub.status.idle":"2021-12-28T23:39:42.182901Z","shell.execute_reply.started":"2021-12-28T23:39:42.173238Z","shell.execute_reply":"2021-12-28T23:39:42.182024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Data,Label=create_data()\nImg = np.array(Data)","metadata":{"execution":{"iopub.status.busy":"2021-12-28T23:39:42.185683Z","iopub.execute_input":"2021-12-28T23:39:42.185892Z","iopub.status.idle":"2021-12-28T23:40:31.942163Z","shell.execute_reply.started":"2021-12-28T23:39:42.185866Z","shell.execute_reply":"2021-12-28T23:40:31.941361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_dataa():\n    dataImage = []\n    Label=[]\n    for img in tqdm(os.listdir('/kaggle/input/ci-sc22-places-and-scene-recognition/test_images/test_images')):\n        path = os.path.join('/kaggle/input/ci-sc22-places-and-scene-recognition/test_images/test_images', img)\n        img_data = cv2.imread(path)\n        img_data = cv2.resize(img_data, (150, 150))\n        dataImage.append(img_data)\n    return dataImage","metadata":{"execution":{"iopub.status.busy":"2021-12-28T23:40:31.94639Z","iopub.execute_input":"2021-12-28T23:40:31.946619Z","iopub.status.idle":"2021-12-28T23:40:31.953697Z","shell.execute_reply.started":"2021-12-28T23:40:31.946591Z","shell.execute_reply":"2021-12-28T23:40:31.952905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test=create_dataa()","metadata":{"execution":{"iopub.status.busy":"2021-12-28T23:40:31.956861Z","iopub.execute_input":"2021-12-28T23:40:31.95706Z","iopub.status.idle":"2021-12-28T23:40:51.580821Z","shell.execute_reply.started":"2021-12-28T23:40:31.957035Z","shell.execute_reply":"2021-12-28T23:40:51.580027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Images[1]","metadata":{"execution":{"iopub.status.busy":"2021-12-28T23:40:51.582046Z","iopub.execute_input":"2021-12-28T23:40:51.582858Z","iopub.status.idle":"2021-12-28T23:40:51.602365Z","shell.execute_reply.started":"2021-12-28T23:40:51.582818Z","shell.execute_reply":"2021-12-28T23:40:51.601568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(Images,ground_truth , test_size=0.3,random_state=None, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-28T23:40:51.603965Z","iopub.execute_input":"2021-12-28T23:40:51.604455Z","iopub.status.idle":"2021-12-28T23:40:52.653327Z","shell.execute_reply.started":"2021-12-28T23:40:51.604416Z","shell.execute_reply":"2021-12-28T23:40:52.652311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Xtrain=[]\nYtrain=[]\nXtest =[]\nYtest =[]\nfor i in range(len(Data)):\n    Xtrain.append(Data[i])\n    Ytrain.append(Label[i])\n\nfor i in range(len(test)):\n    Xtest.append(test[i])\n","metadata":{"execution":{"iopub.status.busy":"2021-12-28T23:40:52.654814Z","iopub.execute_input":"2021-12-28T23:40:52.655109Z","iopub.status.idle":"2021-12-28T23:40:52.668615Z","shell.execute_reply.started":"2021-12-28T23:40:52.655068Z","shell.execute_reply":"2021-12-28T23:40:52.667767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set(style=\"whitegrid\")\nimport os\nimport glob as gb\nimport cv2\nimport tensorflow as tf\nimport keras","metadata":{"execution":{"iopub.status.busy":"2021-12-28T23:40:52.67Z","iopub.execute_input":"2021-12-28T23:40:52.670428Z","iopub.status.idle":"2021-12-28T23:40:57.079602Z","shell.execute_reply.started":"2021-12-28T23:40:52.670371Z","shell.execute_reply":"2021-12-28T23:40:57.078786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow.keras.optimizers as Optimizer","metadata":{"execution":{"iopub.status.busy":"2021-12-28T23:40:57.082917Z","iopub.execute_input":"2021-12-28T23:40:57.083138Z","iopub.status.idle":"2021-12-28T23:40:57.229879Z","shell.execute_reply.started":"2021-12-28T23:40:57.08311Z","shell.execute_reply":"2021-12-28T23:40:57.22907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras import backend as K\n\nfrom keras.layers import Flatten, Dense, Input, Conv2D, MaxPooling2D, Dropout,Convolution2D\nfrom keras.layers import AveragePooling2D, GlobalMaxPooling2D, TimeDistributed\n\nfrom keras.utils import layer_utils\nfrom keras.utils.data_utils import get_file\n\n\nfrom keras.models import Model\nfrom keras.utils import generic_utils\n\nfrom keras import initializers, regularizers","metadata":{"execution":{"iopub.status.busy":"2021-12-28T23:40:57.231298Z","iopub.execute_input":"2021-12-28T23:40:57.231596Z","iopub.status.idle":"2021-12-28T23:40:57.237929Z","shell.execute_reply.started":"2021-12-28T23:40:57.231551Z","shell.execute_reply":"2021-12-28T23:40:57.236742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Initializing the CNN ALexNet\nmodel=keras.models.Sequential([\n    # Convolution Step 1\n    keras.layers.Conv2D(filters=128, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(150,150,3)),\n    keras.layers.BatchNormalization(),\n    \n    # Max Pooling Step 1\n    keras.layers.MaxPool2D(pool_size=(3,3)),\n    \n    # Convolution Step 2\n    keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n    keras.layers.BatchNormalization(),\n    \n    # Max Pooling Step 2\n    keras.layers.MaxPool2D(pool_size=(3,3)),\n    \n    # Convolution Step 3\n    keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n    keras.layers.BatchNormalization(),\n    \n    # Convolution Step 4\n    keras.layers.Conv2D(filters=512, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n    keras.layers.BatchNormalization(),\n    \n    # Convolution Step 5\n    keras.layers.Conv2D(filters=1024, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n    keras.layers.BatchNormalization(),\n    \n    # Max Pooling Step 3\n    keras.layers.MaxPool2D(pool_size=(3,3)),\n    \n    # Flattening Step\n    keras.layers.Flatten(),\n    \n    # Full Connection Step\n    keras.layers.Dense(1024,activation='relu'),\n    keras.layers.Dropout(0.5),\n    keras.layers.Dense(1024,activation='relu'),\n    keras.layers.Dropout(0.5),\n    keras.layers.Dense(6,activation='softmax')      \n])","metadata":{"execution":{"iopub.status.busy":"2021-12-28T23:44:19.127364Z","iopub.execute_input":"2021-12-28T23:44:19.127985Z","iopub.status.idle":"2021-12-28T23:44:19.215778Z","shell.execute_reply.started":"2021-12-28T23:44:19.127881Z","shell.execute_reply":"2021-12-28T23:44:19.214795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential, model_from_json\nfrom keras.layers.core import Dense, Dropout, Activation, Flatten\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.pooling import MaxPooling2D,MaxPool2D\n\nfrom keras.layers import Conv2D, MaxPool2D, Flatten, Dense,BatchNormalization,Activation,Dropout,LeakyReLU\nfrom tensorflow.keras import regularizers","metadata":{"execution":{"iopub.status.busy":"2021-12-28T23:40:59.753121Z","iopub.execute_input":"2021-12-28T23:40:59.753324Z","iopub.status.idle":"2021-12-28T23:40:59.759181Z","shell.execute_reply.started":"2021-12-28T23:40:59.753296Z","shell.execute_reply":"2021-12-28T23:40:59.758465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#KerasModel = tf.keras.models.load_model('./weights.h5', compile=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-28T23:40:59.760644Z","iopub.execute_input":"2021-12-28T23:40:59.761065Z","iopub.status.idle":"2021-12-28T23:40:59.768687Z","shell.execute_reply.started":"2021-12-28T23:40:59.761027Z","shell.execute_reply":"2021-12-28T23:40:59.767931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nprint('Model Details are : ')\nprint(model.summary())\n","metadata":{"execution":{"iopub.status.busy":"2021-12-28T23:40:59.769992Z","iopub.execute_input":"2021-12-28T23:40:59.770326Z","iopub.status.idle":"2021-12-28T23:40:59.790266Z","shell.execute_reply.started":"2021-12-28T23:40:59.770288Z","shell.execute_reply":"2021-12-28T23:40:59.788846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('weights.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow.keras.optimizers as Optimizer","metadata":{"execution":{"iopub.status.busy":"2021-12-28T23:40:59.791849Z","iopub.execute_input":"2021-12-28T23:40:59.792122Z","iopub.status.idle":"2021-12-28T23:40:59.79646Z","shell.execute_reply.started":"2021-12-28T23:40:59.792087Z","shell.execute_reply":"2021-12-28T23:40:59.795682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#KerasModel.compile(optimizer=Optimizer.Adam(0.0001),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\nmodel.compile(optimizer=Optimizer.Adam(0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n","metadata":{"execution":{"iopub.status.busy":"2021-12-28T23:40:59.797913Z","iopub.execute_input":"2021-12-28T23:40:59.798442Z","iopub.status.idle":"2021-12-28T23:40:59.813506Z","shell.execute_reply.started":"2021-12-28T23:40:59.798405Z","shell.execute_reply":"2021-12-28T23:40:59.812831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nXtrain = np.array(Xtrain)\nYtrain =np.array(Ytrain)\nThisModel = model.fit(Xtrain, Ytrain, epochs=80,batch_size=64,verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-12-28T23:40:59.814656Z","iopub.execute_input":"2021-12-28T23:40:59.816625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Xtest\nmodel.save('weights.h5')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(np.array(Xtest))\n\nprint('Prediction Shape is {}'.format(y_pred.shape))\ny_pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Yfinal=[]\nYfinal = np.array(np.argmax(y_pred,axis=1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Yfinal","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Yfinal=np.array(Yfinal)\nYfinal.shape\n# Yfinal.reshape(3407,1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Image_name=[]\ni=0\nfor img in tqdm(os.listdir('/kaggle/input/ci-sc22-places-and-scene-recognition/test_images/test_images')):\n    \n    path = os.path.join('/kaggle/input/ci-sc22-places-and-scene-recognition/test_images/test_images', img)\n    Image_name.append(img)\n    i+=1\n\n# Image_name = np.array(Image_name)\n# Image_name.reshape(3407,1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"my_submission = pd.DataFrame({'Image_name': Image_name, 'Label': Yfinal})\nmy_submission.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}